%!TEX root =  matrix-est.tex
The construction of \cref{thm:combined}
suggests a general procedure for converting
any confidence interval $I_n=I_n(\gap,\pimin)$ for the spectral gap $\gap$,
which
%itself depends 
%on
is expressed in terms of
$\gap$ and $\pimin$,
to a fully empirical confidence interval whose
width matches that of $I_n$ up to lower order terms:
Plug in the empirical bounds of \cref{alg:empest} into the expression defining $I_n$.
\todoa{reworded}
In particular, this suggests that future work should focus on 
closing the gap between the lower and upper bounds on the accuracy
of point-estimation. Another interesting direction is to 
reduce the computation cost: The current cubic cost in the number of states
can be too high even when the number of states is moderate.

Perhaps more important, however, is to extend 
our results to large state space Markov chains:
In most practical applications the state space is continuous
or is exponentially large in some natural parameters.
As follows from our lower bounds, without further assumptions,
the problem of fully data dependent estimation of the mixing time
is intractable for information theoretical reasons.
Interesting directions for future work thus must consider Markov
chains with specific structure. Parametric classes of Markov chains,
including but not limited to Markov chains with factored transition kernels
with a few factors, are a promising candidate for such future investigations.
The results presented here are a first step in the ambitious research agenda
outlined above, and we hope that they will
%pave the way
serve as a point of departure
for
further insights
in the area of fully empirical estimation of Markov chain 
parameters based on a single sample path.
%is full of exciting, important
%and challenging research questions and we hope that our work will
%serve as a source of inspiration for others to consider these questions.
\todoa{rewrote ending}
\if0
The algorithm from Section~\ref{sec:empirical} demonstrates the
feasibility of fully empirical finite-sample confidence bounds on
Markov chain mixing time.
This makes it possible to apply learning methods that require
empirical bounds to many non-iid settings that are commonplace in many
applications.
%One limitation of our techniques is that they are limited to Markov
%chains over finite state spaces.
We expect that future results will generalize and tighten our
analysis, possibly extend it to large (or infinite) state spaces by
adding extra assumptions.

A salient limitation of our approach is the reversibility assumption.
Without the latter, one could still obtain non-trivial finite-sample
estimates.
One possible starting point is to work with a pointwise estimate $\wh
P_{ij}$ and invoke the Ostrowski-Elsner theorem
\citep{stewart1990matrix} to bound the deviation between the empirical
$\hatgap$ and the true $\gap$.
Unfortunately, this bound has an exponential dependence on $d$.
Another problem we leave open for now is to close the gap between the
upper bound in Theorem~\ref{thm:err} and the lower bounds in
Theorems~\ref{thm:lb-pimin} and \ref{thm:lb-gap}. 
\todoc{Reduce space complexity? Assume more structure of $\vP$?
Sometimes $\gap$ is known, but $\pimin$ is not. Does this help?
How about the other way around?
}
\fi
%\todoc{We need to move the references needed in the appendix to after the appendix. 
%This should be possible with some latex package for splitting references..}
%and investigate
%whether the width of the fully empirical confidence interval can be
%shortened to match the width of the theoretical confidence interval.

%The upshot is that now the various Markov PAC learning results stated in
%terms of unknown mixing coefficients
%\citep{gamarnik03,MoRo09}
%can be applied to give nontrivial data-dependent bounds,
%albeit in a limited setting.
